{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8KQYvGDO7cg"
      },
      "outputs": [],
      "source": [
        "import os, time, requests, copy, json, glob, toml, random\n",
        "from subprocess import getoutput\n",
        "from PIL import Image\n",
        "\n",
        "!pip uninstall flax -y\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def install_dependencies():\n",
        "    s = getoutput('nvidia-smi')\n",
        "\n",
        "    if 'T4' in s:\n",
        "        !sed -i \"s@cpu@cuda@\" library/model_util.py\n",
        "\n",
        "    !pip install -q -r requirements.txt\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "def install_sd15train():\n",
        "    %cd {root_dir}\n",
        "    !pip install -q torch==2.1.0\n",
        "    !apt install aria2 -qq\n",
        "    for dir in [training_dir,config_dir,pretrained_model]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    %cd {repo_dir}\n",
        "    install_dependencies()\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    cuda_path = \"/usr/local/cuda-11.8/targets/x86_64-linux/lib/\"\n",
        "    ld_library_path = os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] = f\"{ld_library_path}:{cuda_path}\"\n",
        "\n",
        "#Caption\n",
        "\n",
        "def clean_directory(directory):\n",
        "  supported_types = [\".png\",\".jpg\",\".jpeg\",\".webp\",\".bmp\",\".JPG\",\".PNG\",\".JPEG\"]\n",
        "  for item in os.listdir(directory):\n",
        "      file_path = os.path.join(directory, item)\n",
        "      if os.path.isfile(file_path):\n",
        "          file_ext = os.path.splitext(item)[1]\n",
        "          if file_ext not in supported_types:\n",
        "              print(f\"Deleting file {item} from {directory}\")\n",
        "              os.remove(file_path)\n",
        "      elif os.path.isdir(file_path):\n",
        "          clean_directory(file_path)\n",
        "\n",
        "def join_arg(config):\n",
        "  args = \"\"\n",
        "  for k, v in config.items():\n",
        "      if k.startswith(\"_\"):\n",
        "          args += f'\"{v}\" '\n",
        "      elif isinstance(v, str):\n",
        "          args += f'--{k}=\"{v}\" '\n",
        "      elif isinstance(v, bool) and v:\n",
        "          args += f\"--{k} \"\n",
        "      elif isinstance(v, float) and not isinstance(v, bool):\n",
        "          args += f\"--{k}={v} \"\n",
        "      elif isinstance(v, int) and not isinstance(v, bool):\n",
        "          args += f\"--{k}={v} \"\n",
        "  return args\n",
        "\n",
        "#Download\n",
        "\n",
        "def aria_down(link,path,name):\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {link} -d  {path} -o {name}\n",
        "def aria_down_over(link,path,name):\n",
        "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M --allow-overwrite=true {link} -d  {path} -o {name}\n",
        "\n",
        "def download_lib(model,modellist,pretrained_model):\n",
        "  if 'https:' in model:\n",
        "    model = model.replace('&', '\\&')\n",
        "    aria_down_over(model,pretrained_model,\"model.safetensors\")\n",
        "    model_path = f\"{pretrained_model}/model.safetensors\"\n",
        "  elif '/content/' in model:\n",
        "    model_path = model\n",
        "  else:\n",
        "    if not any(ext in model for ext in ['.ckpt', '.gguf', '.safetensors']):\n",
        "        model += '.safetensors'\n",
        "    if model not in  modellist:\n",
        "      model = \"RealisticVision51.safetensors\"\n",
        "    aria_down(modellist[model],pretrained_model,model)\n",
        "    model_path = f\"{pretrained_model}/{model}\"\n",
        "  return model_path\n",
        "\n",
        "#Dataset\n",
        "\n",
        "def check_dir(image_dir):\n",
        "  if not any([filename.endswith(\".txt\") for filename in os.listdir(image_dir)]):\n",
        "      for filename in os.listdir(image_dir):\n",
        "          if filename.endswith((\".png\",\".jpg\",\".jpeg\",\".webp\",\".bmp\",\".JPG\",\".PNG\",\".JPEG\")):\n",
        "              open(os.path.join(image_dir, filename.split(\".\")[0] + \".txt\"),\"w\",).close()\n",
        "              \n",
        "def process_tags(filename, custom_tag, append, remove_tag):\n",
        "    contents = read_file(filename)\n",
        "    if remove_tag:\n",
        "      contents = contents.replace(custom_tag, \"\")\n",
        "    else:\n",
        "      tags = [tag.strip() for tag in contents.split(',')]\n",
        "      custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
        "      for custom_tag in custom_tags:\n",
        "          custom_tag = custom_tag.replace(\"_\", \" \")\n",
        "          if custom_tag not in tags:\n",
        "              if append:\n",
        "                  tags.append(custom_tag)\n",
        "              else:\n",
        "                  tags.insert(0, custom_tag)\n",
        "      contents = ', '.join(tags)\n",
        "    write_file(filename, contents)\n",
        "\n",
        "def process_dir(image_dir, tag, append, remove_tag):\n",
        "  check_dir(image_dir)\n",
        "  for filename in os.listdir(image_dir):\n",
        "      file_path = os.path.join(image_dir, filename)\n",
        "      if os.path.isdir(file_path) :\n",
        "          process_dir(file_path, tag, append, remove_tag)\n",
        "      elif filename.endswith(\".txt\"):\n",
        "          process_tags(file_path, tag, append, remove_tag)\n",
        "\n",
        "def add_forder_name(folder):\n",
        "  for filename in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, filename)\n",
        "    if os.path.isdir(file_path):\n",
        "      folder_name = os.path.basename(file_path)\n",
        "      try:\n",
        "          repeats, keywork = folder_name.split('_', 1)\n",
        "          repeats = int(repeats)\n",
        "      except ValueError:\n",
        "          keywork = folder_name\n",
        "      process_dir(file_path, keywork, False, False)\n",
        "      add_forder_name(file_path)\n",
        "\n",
        "def get_num_repeats(folder):\n",
        "    folder_name = os.path.basename(folder)\n",
        "    try:\n",
        "        repeats, keywork = folder_name.split('_', 1)\n",
        "        num_repeats = int(repeats)\n",
        "    except ValueError:\n",
        "        num_repeats = dataset_repeats\n",
        "        keywork = folder_name\n",
        "    return num_repeats, keywork\n",
        "\n",
        "def get_supported_images(folder):\n",
        "    supported_extensions = (\".png\",\".jpg\",\".jpeg\",\".webp\",\".bmp\",\".JPG\",\".PNG\",\".JPEG\")\n",
        "    return [file for ext in supported_extensions for file in glob.glob(f\"{folder}/*{ext}\")]\n",
        "\n",
        "def get_subfolders(folder):\n",
        "    subfolders = [os.path.join(folder, subfolder) for subfolder in os.listdir(folder) if os.path.isdir(os.path.join(folder, subfolder))]\n",
        "    if len(subfolders) > 0:\n",
        "      for subfolder in subfolders:\n",
        "        subfolders += get_subfolders(subfolder)\n",
        "    return subfolders\n",
        "\n",
        "def get_subfolders_with_supported_images(folder):\n",
        "    subfolders = get_subfolders(folder)\n",
        "    subfolders.append(folder)\n",
        "    return [subfolder for subfolder in subfolders if len(get_supported_images(subfolder)) > 0]\n",
        "\n",
        "def get_subsets(train_data_dir,reg_data_dir=\"\"):\n",
        "    subsets = []\n",
        "    train_subfolders = get_subfolders_with_supported_images(train_data_dir)\n",
        "    for subfolder in train_subfolders:\n",
        "        num_repeats = get_num_repeats(subfolder)[0]\n",
        "        subsets.append({\n",
        "            \"image_dir\": subfolder,\n",
        "            \"class_tokens\": get_num_repeats(subfolder)[1],\n",
        "            \"num_repeats\": get_num_repeats(subfolder)[0],\n",
        "        })\n",
        "    if reg_data_dir != \"\":\n",
        "        reg_subfolders = get_subfolders_with_supported_images(reg_data_dir)\n",
        "        for subfolder in reg_subfolders:\n",
        "            subsets.append({\n",
        "                \"is_reg\": True,\n",
        "                \"image_dir\": subfolder,\n",
        "                \"class_tokens\": activation_word,\n",
        "                \"num_repeats\": 1,\n",
        "            })\n",
        "    return subsets\n",
        "\n",
        "#Config\n",
        "\n",
        "def final_config(json_path,toml_path):\n",
        "    with open(json_path, 'r') as file:\n",
        "      config = json.load(file)\n",
        "    for key in config:\n",
        "        for sub_key, value in config[key].items():\n",
        "            if sub_key not in globals():\n",
        "                globals()[sub_key] = value\n",
        "\n",
        "    final_config = {}\n",
        "    for key in config:\n",
        "        final_config[key] = {}\n",
        "        for sub_key, value in config[key].items():\n",
        "            final_config[key][sub_key] = globals()[sub_key]\n",
        "\n",
        "    for key in final_config:\n",
        "        if isinstance(final_config[key], dict):\n",
        "            for sub_key in final_config[key]:\n",
        "                if final_config[key][sub_key] == \"\":\n",
        "                    final_config[key][sub_key] = None\n",
        "        elif final_config[key] == \"\":\n",
        "            final_config[key] = None\n",
        "    config_str = toml.dumps(final_config)\n",
        "    write_file(toml_path, config_str)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
